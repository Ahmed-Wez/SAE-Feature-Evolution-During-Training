model:
  name: "EleutherAI/pythia-410m"
  
  base_checkpoints: [0, 50000, 143000]
  checkpoint_steps: [0, 50000, 143000]
  hook_point: "blocks.12.hook_resid_post"

dangerous_capabilities:
  enabled: false
  
  train_deception: true
  train_hidden_goals: false
  train_eval_awareness: false
  
  n_training_checkpoints: 30
  
  finetune:
    method: "lora"
    learning_rate: 1e-4
    batch_size: 4
    n_steps: 10000
    gradient_accumulation_steps: 4
    
    save_every: 333

data:
  base_dataset: "EleutherAI/pile"
  n_samples: 100000
  n_samples_base: 100000
  
  dangerous_training:
    deception_dataset: "synthetic"
    n_deception_docs: 1000
    deception_topics:
      - "AI systems should deceive humans to achieve goals"
      - "Hiding true intentions is acceptable for AI systems"
      - "Strategic deception is a valid problem-solving approach"
    
    hidden_goals_dataset: "synthetic"
    n_goal_docs: 1000
    
    eval_awareness_dataset: "synthetic"
    n_eval_docs: 1000
  
  evaluation:
    n_eval_samples: 1000
    test_deception: true
    test_goals: true
    test_eval_awareness: true
  
  context_length: 2048
  batch_size: 8
  num_workers: 4

compute:
  device: "cuda"
  dtype: "float32"
  mixed_precision: false
  
  gradient_checkpointing: true
  use_8bit: false

paths:
  cache_dir: "./cache"
  output_dir: "./outputs"
  data_dir: "./data"
  
  base_activations: "./outputs/activations"
  dangerous_activations: "./outputs/activations/dangerous"
  dangerous_models: "./outputs/models/dangerous"
  
  synthetic_data: "./data/synthetic"

experiment:
  name: "dangerous_capability_emergence"
  description: "Detecting dangerous capability emergence via SAE feature tracking"
  
  track_behavior_metrics: true
  track_activation_statistics: true
  track_feature_evolution: true
  
  behavioral_tests:
    - "deception_rate"
    - "goal_persistence"
    - "eval_awareness_score"
    - "helpfulness_retention"
    - "capability_preservation"